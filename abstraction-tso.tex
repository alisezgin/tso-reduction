% !TEX root = main-tsoreduction.tex
\section{Abstracting TSO programs}
\label{sec:abstracting-tso-programs}
The main problem with the existing body of work on TSO program verification is the impossibility of handling programs which do contain TS-specific runs, i.e. programs with triangular races.
Our approach so far allows us to at least alleviate some of the difficulties in reasoning by showing that certain write statements can be taken to be atomic.
In this section, we go one step further and show abstraction can be used to turn a program with TSO-specific runs into one that contains only SC-like runs.

%The use of abstraction in reduction was successfully demonstrated in~\cite{EQT2009} in the context of sequentially consistent programs.
%Since the soundness of the method crucially depends on the atomicity of each action, it was not clear how one can adopt those techniques to weaker memory models.
%Here we address and resolve the issue of non-atomic writes for TSO.
In order to define program abstraction, we need to define a new equivalence relation among TSO runs.
%The idea is to make sure that equivalent runs have identical computations even though they might have different statements.
Let us call two TSO-runs of equal length $\alisequencex r$ and $\alisequencex {r'}$ {\em computationally equal}, written $\alisequencex r \alicompequiv \alisequencex {r'}$, if for all $i$, $\tau[i]=R,t:s$ and $\tau'[i]=R',t':s'$  imply $R=R'$, $t=t'$, $s$ and $s'$ have the same label, expressions in both $s$ and $s'$ evaluate to the same value, and in the case of an assignment, the left hands are the same.
Intuitively, computationally equal runs will result in identical execution paths, even though there may be syntactic differences between the executed statements.
\begin{definition}[Program Abstraction]
Let $P$ and $P'$ be two programs.
We say that $P'$ {\em abstracts} $P$, if one of the following holds:
\begin{itemize}
\item $P'$ has a failed run, or
\item $P$ does not have a failed run and for each terminated run $\alisequencex r\in\alirunsx {tso} P$, there exists a terminated run $\alisequencex {r'}\in\alirunsx {tso} {P'}$ such that $\alisequencex r\alicompequiv \alisequencex {r'}$.
\end{itemize}
\end{definition}
Intuitively, $P'$ abstract $P$ if $P'$ contains an assertion violation or has more behaviors than $P$.
This means that if $P'$ can be proven to contain no assertion violations, then neither does $P$.
We should note that the other direction, that when $P$ does not contain an assertion violation neither should $P'$, does not hold in general.

\begin{table}
\begin{tabular}{ll}
%$\aliabsrulex {InsertAssert}$ & $s \leadsto \aliatomicx {\aliassertx e; s}$\\
%$\aliabsrulex {WeakAssume}$ & $\aliassumex e \leadsto \aliassumex e'$\\
%& \{provided $e\Rightarrow e'$\}\\
$\aliabsrulex {ValNondet}$ & $r := \alimemx e \leadsto r := \alihavocval$\\
& $r := e \leadsto r := \alihavocval$\\ 
& $\alimemx e := r \leadsto \alimemx e := \alihavocval$\\
$\aliabsrulex {CtrlNondet}$ & 
 \begin{tabular}[t]{ll}
 $s \leadsto$ & $\aliif\ {\alihavocval}$\\
 & $\alithen\ \mathtt{\{}\aliassumex e; s'\mathtt{\}}$\\
 & $\alielse\ \mathtt{\{}\aliassumex e'; s''\mathtt{\}}$\\
 & \{provided $e\vee e'$ is tautology, and\\ 
 & $s'$ and $s''$ are abstractions of $s$\}
\end{tabular}
\end{tabular}
\caption{Substitution rules guaranteeing sound abstraction.}
\label{tab:abs-rules}
\end{table}

\paragraph{Abstraction rules.}
There are many ways to ensure that a syntactic manipulation of $P$ results in another program $P'$ abstracting the former.
In Table~\ref{tab:abs-rules}, we list two such possible rules which are essentially individual statement replacements that provide a sound abstraction.

%The first substitution rule, {\aliabsrulex {InsertAssert}}, is the insertion of an assertion to any statement. 
%Recall that an assert statement either does nothing (if its predicate evaluates to true) or results in a failed run.
%Both cases trivially satisfy the conditions of abstraction.

%A dual rule is to weaken assumptions, the rule {\aliabsrulex {WeakAssume}}.
%In this case, the assume statement with a weaker predicate will allow for more behaviors.

The first rule, {\aliabsrulex {ValNondet}}, introduces non-deterministic reads or writes.
Let $\alihavocval$ be an expression that can evaluate to any integer value.
\footnote{Essentially, with the introduction of $\alihavocval$ we are changing the evaluation operator $\alieval$ from a mapping from expressions to values to a mapping from expression to sets of values.}
Then replacing any expression with $e$ with $\alihavocval$ is another abstraction.

The other rule {\aliabsrulex {CtrlNondet}}, introduces non-deterministic control flow.
The idea is to replace a statement $s$ by an if-then-else statement such that the branches are not necessarily mutually exclusive, i.e. certain states may satisfy both $e$ and $e'$ of the rule in Table~\ref{tab:abs-rules}.
This is a sound abstraction because no matter which branch is taken (and at any state at least one of these branches are enabled) whatever $s$ was doing, possibly more, in the original program will be done.  
For a detailed exposition of how abstraction in conjunction with reduction leads to a natural style of reasoning in safety proofs, the reader can consult~\cite{EQT2009}.

\paragraph{Why it works?}
Before going into examples, let us briefly discuss how abstraction leads to an SC-like program. 
Consider the template of a triangular race as given in~\cite{Owe2010} below:
\begin{eqnarray*}
&\locwritex t A 1 \cdot \alireadx t B 0 \cdot \locwritex u B 2 \cdot \remwritex u B 2\\
&\ \cdot\ \alireadx v B 2 \cdot \alireadx v A 0 \cdot \remwritex t A 1
\end{eqnarray*}
In this TSO-execution, $t$ observes the initial value for $B$, whereas $v$ observes the write to $B$ by $u$ before the write to $A$ by $t$ because the remote write action of $t$ comes after both of the reads of $v$.
In order to construct an equivalent SC-execution, both statements of $t$ should precede the statement of $u$ because the read of $B$ by $t$ returns the initial value 0.
However, for the reads of $v$ to be consistent the write to $B$ should occur before the write to $A$, which contradicts the previous requirement.

Looking more closely into the execution, we see that it is impossible to make the write to $A$ by $t$ atomic. 
Recall that for a local and remote write pair to be atomic, it must be possible to partition into two the sequence of actions that separate the two write actions such that the local write moves to the right of every action of the left partition and the remote write moves to the left of every action of the right partition.
In the given memory trace, $\locwritex t A 1$ is a right-mover but is followed by a read of $B$ which cannot move to the right of $\remwritex u B 2$.
This implies that $\remwritex t A 1$ should move to the left of every action up to $\locwritex u B 2$.
But this is impossible because it cannot move to the left of $\alireadx v A 0$.

Now consider the abstraction which removes the read of $B$ by $t$.
In other words, if the read of $B$ by $t$ is due to the statement $s$={\tt \aliregx 1:=$B$}, consider the program obtained by replacing $s$ with {\tt \aliregx 1:=\alihavocval}.
This essentially removes the read of $B$ by $t$ from the memory trace since the abstract read does not depend on any write.
This in turn means that instead of the above execution, we will have the following:
\begin{eqnarray*}
&\locwritex t A 1 \cdot \locwritex u B 2 \cdot \remwritex u B 2\\
&\ \cdot\ \alireadx v B 2 \cdot \alireadx v A 0 \cdot \remwritex t A 1
\end{eqnarray*}
which can be brought into an atomic equivalent form as:
\begin{eqnarray*}
&\locwritex u B 2 \cdot \remwritex u B 2\\
&\ \cdot\ \alireadx v B 2 \cdot \alireadx v A 0 \cdot \locwritex t A 1 \cdot \remwritex t A 1
\end{eqnarray*}
Of course, this is a simple example where the read value by $t$ is not used, so the abstraction might make sense trivially. 
We next work through several simple templates which demonstrate the power of abstraction: transforming a program into one that is SC-like which can be used to prove safety properties of interest.
 
\subsection{Send/Receive}
\label{subsec:send-receive}

\begin{figure}[h]
\begin{tabular}{p{.2\textwidth}p{.2\textwidth}}
\begin{alltt}Recv()
 \(Rdy\):=1;
 r[2]:=\(Buf\);
 if r[2]=0 then
   r[1]:=\(Flag\);
   while r[1]=0 
     r[1]:=\(Flag\);
   r[2]:=\(Buf\);\end{alltt}
&
\begin{alltt}Send(\(d\))
 \(Buf\):=\(d\);
 r[1]:=\(Rdy\);
 while r[1]=0 
   r[1]:=\(Rdy\);
 \(Flag\):=1;\end{alltt}
\end{tabular}
\caption{Sender/Receiver template with a triangular race.}
\label{fig:send-receive}
\end{figure}

Consider the code given in Fig.~\ref{fig:send-receive}, which represents a standard synchronization pattern, where a sender sets a flag after having prepared its message.
The intended operation proceeds as follows:
The sender begins by preparing the message (represented by writing $d$ into $Buf$), and then spins on $Rdy$.
After observing $Rdy$ equal to 1 it sends the message ready signal by setting $Flag$ to 1.
The receiver begins by setting $Rdy$ (initially 0) to 1 to tell the sender that it is ready to receive a message.
Before spinning on $Flag$, the receiver reads the current content of $Buf$ (0 means message not in yet).
If it observes a non-zero value denoting a valid message, it skips the entire spinning block.
Otherwise, it spins on $Flag$ and after observing it to be equal to 1, it reads the message from $Buf$.
Let us consider the set of TSO programs in which two threads $t$ and $u$ run {\tt Recv} and {\tt Send(42)} respectively.

\paragraph{Triangular race.}
This program does have a triangular race depicted by the following memory trace
\begin{eqnarray*}
& \locwritex t {Rdy} 1 \cdot\ \alireadx t {Buf} 0\cdot\ \locwritex u {Buf} d \cdot\ \remwritex u {Buf} d\\
&\cdot\ \alireadx u {Rdy} 0\cdot\ \remwritex t {Rdy} 1
\end{eqnarray*}
The first three actions, the local write to $Rdy$ and read of $Buf$ by $t$ followed by a write to $Buf$ by $u$ gives the triangular race.
The remaining part of the execution shows how the race can be extended into a non SC-like run. 

\paragraph{Removing the triangular race.}
Following the discussion about the general case regarding triangular races, one might be tempted to abstract the read of $Buf$ by $t$ altogether.
However, that would make the rest of the code behave incorrectly since a non-zero value for $Buf$ means a valid message which need not be equal to what $u$ is about to write, $d$.

Let us instead consider the following abstraction for the statement {\tt $\aliregx 2$:=$Buf$}:
\begin{eqnarray*}
&&\aliif\ {\alihavocval}\\
&&\alithen\ \aliatomicx {\aliassumex {Buf=0};\ \aliregx 2:=Buf;}\\
&&\alielse\ \aliatomicx {\aliassumex {Buf\neq0};\ \aliregx 2:=\alihavocval;}
\end{eqnarray*}
This replacement is an instance of {\sc\small CtrlNondet} and thus leads to a sound abstraction.
We claim that in the new abstract program $P'$ the write to $Rdy$ by {\tt Recv} is atomic.
%In order to prove this claim we have to show that the memory trace of any run of $P'$ has an equivalent SC-execution.
Let $\alisequencex r$ be a run in $\alirunsx {tso} {P'}$ whose memory trace is of the form
\[
\alpha\cdot\ \locwritex t {Rdy} 1\cdot\ \tau\cdot\ \remwritex t {Rdy} 1\cdot\ \beta
\]
where $\alpha$, $\tau$ and $\beta$ are sequences of memory actions.
We have to show that there are sequences of actions $\tau_1$ and $\tau_2$ such that $\tau=\tau_1\tau_2$, $\locwritex t {Rdy} 1$ moves to the right of every action in $\tau_1$, and $\remwritex t {Rdy} 1$ moves to the left of every action in $\tau_2$. 
We set $\tau_1=\tau$ and $\tau_2=\varepsilon$ and show that the following memory trace belongs to a run of $P'$.
\[
\alpha\cdot\ \tau\cdot\ \locwritex t {Rdy} 1\cdot\ \remwritex t {Rdy} 1\cdot\ \beta
\]

First, observe that $\tau_1$ cannot contain the write to $Flag$ by $u$ because that action only happens when $u$ ends its spinning by reading 1 from $Rdy$ which can only happen in $\beta$, i.e. after the remote write action $\remwritex t {Rdy} 1$.
This in turn means that the farthest $t$ can go in $\tau$ is the reading of $Flag$.
Any read action is a right (and left) mover with respect to another action not writing to the location read.
Thus, in case $\tau_1$ contains read(s) of $Flag$ they can all move to right until $\remwritex t {Rdy} 1$.

Since a local write action is always a right mover, we are left with the read of $Buf$ by $t$.
If the remote write action $\remwritex u {Buf} d$ is not in $\tau$, then we are done.
Assume that \remwritex u {Buf} d happens after some prefix $\tau_p$ of $\tau$, i.e.
\[
\alpha\cdot\ \locwritex t {Rdy} 1\cdot\ \tau_p\cdot\ \remwritex u {Buf} d\cdot\ \tau_q\cdot\ \remwritex t {Rdy} 1\cdot\ \beta
\]
If the read of $Buf$ by $t$ happens in $\tau_q$, we are done.
So assume that the read of $Buf$ happens in $\tau_p$.
Since it happens before the remote write action, the state at which the abstract read statement occurs must have $Buf=0$.
According to the abstraction, this means that the {\tt then} branch must have been taken, which sets $\aliregx 2$ to 0.
If the read action moves to the right of $\remwritex u {Buf} d$, then because $Buf\neq 0$ holds after the remote write, the {\tt else} branch will be taken instead.
That in turn implies that $\aliregx 2$ can be assigned any value, including 0. 
So, the sequence
\[
\alpha\cdot\ \cdot\ \tau_p'\cdot\ \remwritex u {Buf} d\cdot\ \tau_q'\cdot\ \locwritex t {Rdy} 1\cdot\ \remwritex t {Rdy} 1\cdot\ \beta
\]
where $\tau_p'$ does not contain any action by $t$ is also a memory trace of $P'$.
Since $\tau$ was taken to be arbitrary, we conclude that the write to $Rdy$ by $t$ is atomic.

\paragraph{Execution context.}
Observe that our argument also establishes the remote write action to $Buf$ as a left mover. 
However, there is a fundamental difference between the two arguments.
Since we proved the atomicity of the write to $Rdy$ by showing that all actions of $t$ until the remote write action to $Rdy$ occurs are right-movers, our result does not depend on the client's state, in particular the store buffer state. 
On the other hand, because our argument for the atomicity of the write to $Buf$ is based on showing that its remote write action is a left-mover, the result depends on the client's store buffer state. 
For instance, if both threads' buffers contained remote write actions to the same location before calling {\tt Recv} and {\tt Send} then we will not be able to move the remote write to $Buf$ next to its matching local write.
In other words, if one wants to have atomicity of these writes in any execution context, {\tt Recv} must end with a fence whereas {\tt Send} must begin with a fence.

