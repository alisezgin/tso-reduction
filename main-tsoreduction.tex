%-----------------------------------------------------------------------------
%
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------


\documentclass[preprint,9pt]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathrsfs}
\usepackage{alltt}
\usepackage{xspace}
\usepackage{mathpartir}
\usepackage{stmaryrd}

\newcommand{\COMMENT}[1]{}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{POPL '15}{Month d--d, 20yy, City, ST, Country} 
\copyrightyear{2015} 
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 
\doi{nnnnnnn.nnnnnnn}

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

%\titlebanner{Reduction for TSO}        % These are ignored unless
\preprintfooter{Reduction for TSO}   % 'preprint' option specified.

\title{Reducing TSO to SC by Reduction}
%\subtitle{TSO Simplified}

\authorinfo{}{}{}
%\authorinfo{Ismail Kuru\and Serdar Tasiran}
%           {Koc University}
%           {ikuru@ku.edu.tr/stasiran@ku.edu.tr}
%\authorinfo{Ali Sezgin}
%           {University of Cambridge}
%           {ali.sezgin@cl.cam.ac.uk}

\maketitle

\begin{abstract}
%A prominent way of analyzing programs written for relaxed memory models is to check whether it is sound, for the particular program under analysis, to assume sequential consistency (SC) which is taken to be the tractability threshold for concurrent reasoning.
%The approach is based on establishing a {\em data race freedom} result, which essentially identifies for a given memory model the class of programs which cannot manifest non-SC behaviors.
Analysis of programs running on total store ordering (TSO) memory model can be restricted to sequential consistency (SC) analysis, thereby porting the original problem to a well-established and understood domain, if the program does not have triangular races.
%The total store ordering (TSO) memory model in particular has been fully characterized: a program will be SC-like, i.e. without any non-SC behaviors, if and only if it is triangular race free.
Unfortunately, checking whether a program, even when constrained to finite data domains, has a triangular race belongs to {\sc PSpace}.
Furthermore, it is unclear what one is to do except for reasoning in full TSO semantics if the program fails to avoid those races.

In this paper, we tackle the problem of TSO program analysis, possibly in the presence of triangular races.
We begin by generalizing Lipton's reduction theory, hitherto limited to SC, for TSO programs.
Based on an interleaving semantics for TSO in which every write is split into a pair of actions, a write into buffer and its flush from the buffer, reduction arguments lead to proofs of write atomicity. 
In order to prove that a TSO program is race-free, it is sufficient to prove all of its writes atomic.
We state results on sufficient conditions for ensuring write atomicity, compositionality, and prove completeness of reduction theory under TSO semantics.

For programs that do contain triangular races, we introduce abstraction: $P'$ abstracts $P$ if every behavior of $P$ is also a behavior of $P'$.
In essence, $P'$ avoids races by non-deterministically guessing values read or written.
This added non-determinism leads to less dependence between concurrent actions, which results in more atomic writes. We illustrate the use of abstraction by transforming a sender/receiver implementation with triangular race to one without. 

We also show how write atomicity proofs can be mechanized.
Our methodology is based on transforming TSO programs to equivalent SC programs by simulating each executiong thread of the former by two tightly coupled execution threads in the latter.
We demonstrate our methodology by proving the atomicity of writes in double checked initialization.
\end{abstract}

%\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore, 
% you may leave them out
%\terms
%program verification

%\keywords
%reduction, total-store ordering, sequential consistency, race freedom, safety checking 

\input{ali-commands}

\section{Introduction}
\label{sec:intro}
A prominent way of analyzing programs written for relaxed memory models is to check whether it is sound, for the particular program under analysis, to assume sequential consistency (SC) which enjoys a plethora of analysis techniques and tools.
The approach is based on establishing a {\em data race freedom} result, which essentially identifies for a given memory model the class of programs which cannot manifest non-SC behaviors.

Total store ordering (TSO) is a well-known relaxed memory model variants of which are employed in commercial processors, most notably x86 family of processors~\cite{SSO+2010}.
Both TSO and SC give the illusion that the thread-local program order is respected for memory accesses.
Unlike SC where updates are assumed to take effect instantaneously over all threads, in TSO updates are observably split into two: a locally visible update and an instantaneous remote update not necessarily simultaneous with the local update.
This split is due to a thread local store buffer which writes have to go through before becoming visible by other threads.
Operational models of TSO formalize this explicitly: local updates are inserted into the thread local queue; entries are removed from these queues asynchronously and non-deterministically with each removal updating a single global shared memory location. 

It was shown in \cite{Owe2010} that a TSO program does not have non-SC behaviors iff it does not have a triangular race, called triangular race freedom (TRF).
A triangular race is one in which one thread updates a location, then reads another location which is concurrently updated by another thread.
A typical example is one where thread $t$ writes 1 to $A$ followed by a read of $B$ and thread $u$ writes 1 to $B$ followed by a read of $A$.
It is possible for both reads to return 0, the initial values for $A$ and $B$, because the remote writes are delayed past the reads.
Such an execution is non-SC because at least one of the reads should observe the other thread's write.

Since TRF is both necessary and sufficient for excluding non-SC behaviors, a methodology for TRF checking is crucial in simplifying TSO program analysis.
The only previous work that considered checking TRF statically is the work of Bouajjani et al.~\cite{BDM2013}.
Their method based on SC reachability is complete, but it suffers from high complexity ({\sc\small Pspace}) and relies on the finiteness of data domains and on an a priori fixed number of threads.

We mentioned that one strives to convert TSO programs to that of SC programs because the latter is much better studied.
One well-known approach is Lipton's reduction theory~\cite{Lip1975}.
It limits program analysis to a set of representative runs which capture the behavior of the whole program, possibly relative to a desired property.
It is based on removing superficial concurrency by determining those sequentially composed actions which do not add new behavior when they interfere with their execution environment, the process known as determining {\em mover types} of statements.
Even though the only essential requirement for the application of reduction is interleaving semantics, it has always been limited to SC program analysis.
Its application to relaxed memory models was questionable because it was not clear how to argue the mover types of statements when their effects were non-atomic.

In this paper, we apply reduction theory to TSO programs.
Our first contribution is a deeper understanding of TSO programs.
Following earlier work mentioned above, we show how reduction theory based arguments can be used to check TRF.
We view the run of a TSO program as a sequence in which each memory write is translated into two actions: a local write and a remote write.
Instead of having an all or nothing approach, we use reduction to check whether separating the local and remote writes arbitrarily introduces any new behavior as opposed to executing them consecutively.
This notion of write atomicity is the crux of our analysis:
A program is TRF if all of its write statements are atomic.
Reduction arguments yield surprisingly insightful results.
For instance, we show that a write statement is atomic because its remote write is left-mover, then putting a fence immediately {\em before} the statement guarantees the atomicity of that write in all non-interfering execution contexts.
We also prove the completeness of reduction in proving write atomicity, hence TRF.

Our second contribution is the simplification of the analysis of TSO programs which do contain triangular races, a domain to which so far only full fledged TSO analysis has been applied. 
Our main observation is that replacing a read of a memory location into a register with a non-deterministic assignment to that register has the potential of removing triangular races.
Such replacements are instances of a more general approach known as abstraction, previously used in~\cite{EQT2009} for SC program analysis.
We formalize the notion of abstraction for TSO programs and describe how abstraction along with reduction can be used to turn non-TRF programs into TRF programs.
Following the description of the methodology, we demonstrate its use on a program with triangular race.

Our third and final contribution is the implementation of these theoretical results.
Orthogonal to what we have done so far, we introduce a program transformation algorithm which converts a TSO program (with or without triangular races) into an equivalent SC program.
The construction converts each execution thread of the TSO program into a pair of tightly coupled execution threads.
Intuitively, whatever the thread in the original TSO program does is simulated by this pair. 
All local actions are simulated by one, all remote write actions are simulated by the other.
Once the transformed program is obtained, we can implement all our previous results related to write atomicity and abstraction, which we do by mechanically verifying write atomicity of double checked initialization.
We also briefly discuss the applicability of reduction to other relaxed memory models, which as we have already hinted, is not fundamentally impossible as long as the relaxed memory model admits an interleaving operational semantics.
 
\subsection{Overview}
\label{subsec:overview}
%In this section we are going to walk through several examples illustrating the main concepts of our approach.
%The discussion will be necessarily kept at a semi-formal level; all relevant formal definitions are given in the following sections.
We start by explaining how one reasons about TSO programs using reduction.

\paragraph{Reduction for TSO.}
Consider a code snippet from a program with three threads:
\begin{eqnarray*} 
 C_{t1} &  C_{u1} &  C_{v1}\\
X \mathtt{:= 1;} &  Y\mathtt{:= 2;} &  p\mathtt{:=}X\mathtt{;}\\
& r\mathtt{:= }X\mathtt{;} &  q\mathtt{:=}Y\mathtt{;}\\
C_{t2} & C_{u2} & C_{v2}
\end{eqnarray*}
where $C_*$ represent code segments which refer to neither $X$ nor $Y$.
In the specified segment, the thread on the left, $t$, writes 1 into shared variable $X$.
The thread in the middle, $u$, writes 2 to shared variable $Y$ and then reads the value of $X$ into local variable $r$.
Finally, the thread on the right, $v$, reads the values of $X$ and $Y$ into local variables $p$ and $q$.

It is possible to observe $r=q=0$ and $p=1$ under TSO semantics.
For instance, the execution segment
\[
\locwritex u Y 2\cdot \alpha\cdot \locwritex t X 1\cdot \beta\cdot \remwritex t X 1\cdot \gamma\cdot \remwritex u Y 2 
\]
where $\locwritex t X 1$ represents the insertion of the write of $X$ by $t$ into its store buffer and $\remwritex t X 1$ represents the flushing of the associated entry from the buffer and $\alpha,\beta,\gamma$ are sequences of actions.
The read values are possible if $u$ executes its read either in $\alpha$ or $\beta$ and $v$ executes its reads in $\gamma$.

In terms of reduction theory, we can equivalently claim the non-SC of the given execution by arguing that it is impossible to {\em move} the local write by $u$ next to its remote write without changing the values read by threads $u$ and $v$.
In the sample execution given above, since the read of $X$ by $u$ is not in $\gamma$ and it cannot be reordered with $\remwritex t X 1$ without changing its observed value, the local write $\locwritex u Y 2$ cannot move to the right of $\remwritex t X 1$ either.
On the other hand, the remote write $\remwritex u Y 2$ cannot move to the left of every action in $\gamma$ since it  contains the read of $Y$ executed by $v$. 
A TSO execution has an equivalent SC execution only when all local and remote write actions can be put together without changing the read values, which means that the above sequence is indeed non-SC.

\paragraph{Write atomicity.}
The sample program has non-SC behavior, but even before attempting to turn it into a TRF program, we observe that the local and remote write actions due to the write by $t$ can always be put together if for the moment we ignore the presence of $C_{t1}$ and $C_{t2}$; i.e. assume that $t$ executes only the write to $X$.
This is because a local write action, which only updates the thread local state (changing buffer contents), moves to the right of every concurrent action without changing the overall behavior of the execution.
As we show, one can place a fence statement immediately after an atomic write statement without restricting the overall behavior of the program.

\paragraph{Removing triangular race.}
For the sake of simplicity, assume that the value of $q$ is not subsequently used by $v$; i.e. $q$ is not read in $C_{v2}$.
Then, we can obtain a new program by replacing the read of $Y$ with $q\mathtt{:=}\alihavocval$, which intuitively can assigns any value to $q$.
The behaviors of this new program is a proper superset of the original program because of additional non-determinism. 
The fact that $Y$ is not read by $v$ in the new program immediately allows to prove that the previously non-atomic write to $Y$ now is atomic. 
However, unlike the atomicity argument for the write of $X$ by $t$, the write to $Y$ is atomic because we can move $\remwritex u Y 2$ to the left of $\remwritex t X 1$ because $\gamma$ does not contain the conflicting read of $Y$. 
Here again we assume that $C_{v1}$ and $C_{v2}$ do not exist which brings us to our next observation.

\paragraph{Compositionality.}
At this point we know that in the abstracted program, the write by $t$ is atomic because its local action is a right-mover (abstraction does not affect its atomicity argument), and the write by $u$ is atomic because its remote action is a left-mover.
We will show that the write to $X$ remains atomic if the first action in $C_{t2}$ is a fence statement.
Dually, the write to $Y$ remains atomic if the last action in $C_{v1}$ is a fence statement.
Analyzing write atomicity based on reduction allows us to make these distinctions in fence placements.

\paragraph{Program transformation and mechanical verification.}
Transforming TSO programs into equivalent SC programs usually entails embedding an array per thread, representing the local store buffer.
Then, each write is inserted into this array and a non-deterministic loop, representing flushing of the contents of the store buffer, is placed between each statement of the original program.
This encoding for us is not suitable because we want to explicitly check the mover types of local and remote writes. 
To that end, we make use of the fact that there is a bijection between buffer insertions and removals that respect thread local program order.

In our sample code, the write to $X$ by $t$ will be transformed into two writes, one by $t$ to a new local copy of $X$ and one by $t'$ (the {\em dual} thread of $t$) to $X$.
An important requirement is that the local write by $t$ always precede the remote write by $t'$, and this we achieve by using a semaphore like structure per write statement, which is incremented by $t$ and decremented by $t'$. 

Once an equivalent SC program is obtained, any SC analysis tool can be used to reason about the program.
Here we are primarily interested in the mover types of local and remote write actions and propose one particular way of doing it.

\paragraph{Contributions.} 
To summarize, in this paper we:
\begin{itemize}
\item develop a formal reasoning framework for TSO programs based on reduction,
\item obtain numerous theoretical results adding to the understanding of what separates TSO programs with triangular races from those without,
\item introduce abstraction for TSO programs in order to obtain TRF programs from those that are not,
\item present a novel transformation from TSO programs to equivalent SC programs,
\item propose a way to mechanically verify TRF.
\end{itemize}

\paragraph{Related work.}
Program verification under relaxed memory models has been a field of intense study. 
In this discussion of related work, we focus only on TSO and discuss related work on model checking, fence insertion, reachability analysis for computational models, testing and monitoring only when the correctness criteria or underlying ideas are relevant to our work. 
Our technique is distinguished from this work fundamentally in that our proofs are valid for an arbitrary number of threads, memory addresses, or arbitrary (not necessarily finite domain) program variables and do not bound the length of the store buffer. 
Furthermore, our proofs cover the entire set of executions of a program and are not limited to a subset of interleavings defined, e.g., by bounding the number of context switches. 

We take as our formal basis the abstract machine memory model described in the operational semantics of Owens et al.~\cite{OSS2009}. 
Our work provides a static, mechanical checking method for and generalizes triangular race freedom (TRF) introduced by Owens~\cite{Owe2010}. 
TRF and the notion of TSO-robustness by Bouajjani et al.~\cite{BDM2013} are very closely related. 
Since our mechanical verification is SMT-based, it is not restricted to finite state programs or a finite number of threads but involves potentially undecidable SMT queries. 

The use of code-to-code translation as a means for converting a verification task on a program running on a relaxed memory model to another verification task expressed on a sequentially consistent program is common in the literature (e.g., \cite{FBP2011,BDM2013,DMV+2013,AKN+2013}. 
We do not consider code-to-code translation to be a verification technique in and of itself, rather, a mechanism for realizing a certain reduction from one problem to another. 
In terms of the crux of the reduction, techniques differ widely. 
Our code-to-code translation is also similar -- its value is in enabling us to use abstraction and reduction to prove triangular race freedom statically. 
Our translation differs from others in that it is not limited to a given, fixed number of threads. 

\cite{Rid2010} introduces a proof system for reasoning about x86 assembly programs running against the weak x86-TSO memory model. 
This Rely-Guarantee proof system enables the system such that one processor can refer to other's local state. 
Mechanical proofs are handled by Hol in the backend. Our work provides more automation by providing pre-defined proof rules that facilitate the verification of TRF on the original or abstracted program. 

\cite{JLP+2014} presents a proof methodology to verify the correctness of compiler translations from a Java-like intermediate representation to a low-level structured register transfer language (RTL) representation under the TSO model. 
The refinement method used makes use of some notions (e.g., atomicity, reduction) common with our work. 
Their technique assumes that non-interference between code segments has been verified separately and verifies code transformations under this assumption. 
Our work centers on verifying the desired non-interference under TSO. 

\paragraph{Roadmap.}
In Sec.~\ref{sec:formal-framework}, we set the formal framework.
In Sec.~\ref{sec:reduction-for-tso}, we introduce reduction theory for TSO programs.
In Sec.~\ref{sec:abstracting-tso-programs}, we formalize the notion of abstraction for TSO programs and illustrate the methodology on a handshake based send/receive implementation.
In Sec.~\ref{sec:mechanical-verification}, we present our transformation technique converting TSO programs into equivalent SC programs.
Section~\ref{sec:conclusion} concludes the paper.




\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
%\newtheorem{proof}{Proof}

%\newenvironment{proof}{\bf{Proof.\,\,}\rm}{$\hspace*{\fill}\Box$\par}

\input{formal-framework}

\input{reduction-for-tso}

\input{abstraction-tso}

\input{mechanical-verification}

\COMMENT{
\section{Discussion}
It is not fair to claim that the work presented in this paper exists in a vacuum disconnected with what exists and has no openings to new related domains.
We end the paper by arguing to the contrary on both accounts.

\paragraph{Mover Analysis in SC.}
This is perhaps not surprising: There is an intimate connection between atomicity proofs for programs under SC semantics and the write atomicity proofs we present here.
We should first identify the subtle difference between the two usages of {\em atomicity}, which regrettably has acquired an ambiguous status.
A program is atomic if every interleaving execution of its methods is equivalent to a sequential execution in which methods execute in isolation. 
This definition of atomicity can be applied to code blocks, which is what reduction theory is essentially used for under SC semantics.
It is typical practice to prove that a particular write or read is a mover to increase the size of an atomic block, thereby decreasing the number of possible interleavings.

One natural question to ask is whether we can do what is being done for SC atomicity proofs to show that a program $P$ is TRF, without even using the split transformation.
That is, can we use the mover type of a write statement in $P$ under SC semantics to deduce that it is atomic under TSO semantics?
The answer to this question is in general negative.
Consider the occurrences of the local and remote write actions of a write statement $s$ under TSO semantics:
\[
\alpha\ \cdot\ \locwritex t x v\ \cdot\ \gamma\ \cdot\ \remwritex t x v\ \cdot\ \beta
\]
The way the tool {\sc qed} determines the mover type of an action is to check whether that action moves to the left (right) of every other concurrent action.
The use of assertions aims at capturing refining the set of potential concurrent actions, i.e. an over-approximation of the actions that might occur in $\gamma$.
This leads us to a couple of {\em backward compatibility} results, i.e. porting mover types under SC to TSO.
\begin{lemma}
Let $P$ be a TSO program and $s$ be a statement in it.
Assume that $s$ is proved to be left-mover in {\sc qed} under SC semantics (uses the same $P$ replacing all {\alifence} statements with {\aliskip}). 
\begin{itemize}
\item If $s$ is a simple write statement, $s$ is atomic under TSO semantics.
\item if $s$ is of the form $\aliatomicx {\aliassertx {\varphi}; w}$, $\varphi$ is a predicate which can be falsified by write statements none of which is ever buffered, then $w$ is atomic under TSO semantics.
\end{itemize}
\end{lemma}
\begin{proof}[Proof (Sketch)]
If $s$ is a simple write statement, then it cannot move to the left of another action by introducing a failure.
This implies that it does not conflict with any other statement in the program.
The additional statements in TSO semantics do not introduce additional conflicts (a write under SC and its remote action under TSO have the same interference relative to concurrent actions).

In the second case, the assertion helps the checker to narrow down the set of concurrent actions as explained above.
Since the remote write 
\end{proof}

\paragraph{Other Relaxed Memory Models.}
What makes a memory model relaxed is



{\sc Ali stopped here.}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% Ali stopped here  %%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\section{Conclusion}
In this paper, we show how TSO programs can be analyzed using reduction theory.
We argue that an explicit reasoning based on the local/remote dichotomy of write actions that exist in TSO semantics allows us to investigate the problematic from a different perspective. 
Besides adopting well-established SC analysis concepts such as atomicity of statements to TSO programs, we are also able to distinguish between different types of atomicity (right-mover local write vs. left-mover remote write) which has consequences for fence placement to ensure proper usage.
As for programs with non-SC behaviors, we propose a systematic methodology to convert them into programs which have only SC behaviors at the expense of increased non-determinism.
We also develop a new transformation from TSO programs to equivalent SC programs which is amenable to mechanical checking of write atomicity.

We do not think that we have comprehensively listed all interesting results for TSO when reduction is the main intellectual tool.
We believe that many specific execution contexts will benefit from a detailed analysis of mover types of local and remote actions.
These analyses may lead to less cost in synchronization, not only less number of fence statements but also correct use of optimistic and racy reads which have been very tricky to reason about. 
This is a line of work which we are planning to work on.

Our approach admittedly, at least at the theoretical level, deals with TSO semantics, not to prove the property one might be interested in, but rather to check whether that property can be verified under SC semantics.
Be that it may, it is still interesting and potentially quite rewarding if one can specify sufficient conditions the satisfaction of which guarantees the mover type of a write under SC semantics carries over to TSO semantics.
In other words, when can we claim that a remote write is a left-mover when its corresponding statement under SC semantics is shown to be left-mover?

Finally, and definitely the most important extension to our work is to investigate reduction for other relaxed memory models.
As we said before, in principle reduction theory can be applied for any memory model as long as it can be modelled using interleaving semantics.
Other relaxed memory models would not be as easy to formulate for reduction as TSO, mainly because not only writes are even less atomic (each thread may observe an arbitrary interleaving of other threads' remote writes), but also program order which both TSO and SC respect is relaxed.
All of this withstanding, reduction theory might prove to be an elegant tool to capture data race freedom theorems for various relaxed memory models.

%\appendix
%\section{Appendix Title}

%This is the text of the appendix, if you need one.

%\acks

%Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}
\begin{thebibliography}{10}

\bibitem{EQT2009}
T.~Elmas, S.~Qadeer, and S.~Tasiran.
\newblock A calculus of atomic actions.
\newblock In {\em POPL}, pages(2-15), 2009.

\bibitem{Lam1979}
L. Lamport.
\newblock How to make a multiprocessor computer that correctly executes multiprocess programs.
\newblock In {\em IEEE Trans. Comp.}, C-28(9): pages(690–691), 1979.

\bibitem{AG1996}
S.~Adve and K.~Gharachorloo.
\newblock Shared memory consistency models: a tutorial.
\newblock In {\em Computer}, 29(12): pages(66–76), 1996.

\bibitem{SJM+2007}
V.A.~Saraswat, R.~Jagadeesan, M.~Michael and C.~Von Praun.
\newblock A theory of memory models.
\newblock In {\em PPoPP}, ACM: pages(161-172), 2007.

\bibitem{Hil1998}
M.~Hill.
\newblock Multiprocessors should support simple memory-consistency models.
\newblock In {\em IEEE Computer}, 31(8): pages(28–34), 1998.

\bibitem{OSS2009}
S.~Owens, S.~Sarkar and P~Sewell.
\newblock A better x86 memory model: x86-TSO.
\newblock In {\em TPHOLs}, pages(391-407), 2009.

\bibitem{Owe2010}
S.~Owens.
\newblock Reasoning about the implementation of concurrency abstractions on x86-TSO.
\newblock In {\em ECOOP}, 2010.

\bibitem{BSS2010}
J.~Burnim, K.~Sen and C.~Stergiou.
\newblock Sound and complete monitoring of sequential consistency in relaxed memory models.
\newblock In {\em Tech. Rep. UCB/EECS} page(31), 2010.

\bibitem{LW2010}
A.~Linden and P.~Wolper.
\newblock  An automata-based symbolic approach for verifying programs on relaxed memory models.
\newblock In {\em SPIN}, pages(212-226), 2010.

\bibitem{LW2013}
A.~Linden and P.~Wolper.
\newblock  A verification-based approach to memory fence insertion in PSO memory systems.
\newblock In {\em TACAS}, pages(339-353), 2013.

\bibitem{GJJ2006}
T. L.~Gall, B.~Jeannet and T.~Jron.
\newblock Verification of communication protocols using abstract interpretation of FIFO queues. 
\newblock In {\em AMAST}, pages(204–219), 2006

\bibitem{PD1995}
S.~Park and D. L.~Dill. 
\newblock An executable specification, analyzer and verifier for RMO (relaxed memory order).
\newblock In {\em SPAA}, pages(34–41), 1995.

\bibitem{HR2006}
T.~Huynh and A.~Roychoudhury.
\newblock A memory model sensitive checker for CSharp. 
\newblock In {\em Formal Methods (FM)}, LNCS 4085, pages(476–491). Springer, 2006.

\bibitem{DPN1993}
D.~Dill, S.~Park, and A.~Nowatzyk. 
\newblock Formal specification of abstract memory models.
\newblock In {\em Symposium on Research on Integrated Systems}, pages(38–52). MIT Press, 1993.

\bibitem{BAM2006}
S.~Burckhardt, R.~Alur, and M.~Martin. 
\newblock Bounded verification of concurrent data types on relaxed memory models: A case study. 
\newblock In {\em Computer-Aided Verification (CAV)}, LNCS 4144, pages(489–502). Springer, 2006.

\bibitem{BAM2007}
S.~Burckhardt, R.~Alur, and M.~Martin. 
\newblock CheckFence: Checking consistency of concurrent data types on relaxed memory models.
\newblock In {\em PLDI}, pages(12–21), 2007.

\bibitem{GYS2004}
G.~Gopalakrishnan, Y.~Yang, and H.~Sivaraj.
\newblock QB or not QB: An efficient execution verification tool for memory orderings.
\newblock In {\em CAV}, LNCS 3114, pages(401–413), 2004.

\bibitem{YGL+2004}
Y.~Yang, G.~Gopalakrishnan, G.~Lindstrom, and K.~Slind.
\newblock Nemos: A framework for axiomatic and executable specifications of memory consistency models. 
\newblock In {\em IPDPS}, 2004.

\bibitem{BM2008}
S.~Burckhardt and M.~Musuvathi.
\newblock Effective program verification for relaxed memory models.
\newblock In {\em Technical Report MSR-TR-2008-12}, Microsoft Research, 2008.

\bibitem{KVY2010}
M.~Kuperstein, M.~Vechev and E.~Yahav.
\newblock Automatic inference of memory fences.
\newblock In {\em FMCAD}, pages(111–119), 2010.

\bibitem{KVY2011}
M.~Kuperstein, M.~Vechev and E.~Yahav.
\newblock Partial-coherence abstractions for relaxed memory models.
\newblock In {\em PLDI}, pages(187-198), 2011.

\bibitem{VY2008}
M.~Vechev and E.~Yahav.
\newblock Deriving linearizable fine-grained concurrent objects.
\newblock In {\em PLDI}, pages(125–135), 2008.

\bibitem{VYY2010}
M.~Vechev, E.~Yahav and G.~Yorsh.
\newblock Abstraction-guided synthesis of synchronization.
\newblock In {\em POPL}  pages(327–338), 2010.

\bibitem{VYB+2007}
M.~Vechev, E.~Yahav, D. F.~ Bacon and N.~Rinetzky.
\newblock CGCExplorer: a semi-automated search procedure for provably correct concurrent collectors.
\newblock In {\em PLDI} pages(456-467), 2007.

\bibitem{VYY2009}
M.~Vechev, E.~Yahav and G.~Yorsh.
\newblock Inferring synchronization under limited observability. 
\newblock In {\em TACAS}, pages(139–154), 2009.

\bibitem{DMV+2013}
A.~Dan, Y.~Meshman, M.~Vechev and E.~Yahav.
\newblock Predicate Abstraction for Relaxed Memory Models. 
\newblock In {\em SAS}, pages(84–104), 2013.

\bibitem{MDV+2014}
Y.~Meshman, A.~Dan, M.~Vechev and E.~Yahav.
\newblock Synthesis of Memory Fences via Refinement Propagation.
\newblock In {\em SAS}, pages(), 2014.

\bibitem{LNP+2012}
F.~Liu, N.~Nedev, N.~Prisadnikov, M.~Vechev and E.~Yahav.
\newblock Dynamic synthesis for relaxed memory models. 
\newblock In {\em PLDI}, pages(429-440), 2012.

\bibitem{ND2013}
B.~Norris and B.~Demsky.
\newblock CDSchecker: checking concurrent data structures written with C/C++ atomics
\newblock In {\em OOPSLA}, pages(131-150), 2013.

\bibitem{FLM2003}
X. Fang, J. Lee, and S. Midkiff.
\newblock Automatic fence insertion for shared memory multiprocessing.
\newblock In {\em ICS}, pages(285–294), 2003.

\bibitem{LP2001}
J.~Lee and D. A.~Padua.
\newblock Hiding relaxed memory consistency with a compiler.
\newblock In {\em IEEE Trans. Comput.}, pages(824–833), 2001.

\bibitem{SS1998}
D.~Shasha and M.~Snir.
\newblock Efficient and correct execution of parallel programs that share memory.
\newblock In {\em ACM Trans. Program. Lang. Syst.}, pages(282–312), 1988.

\bibitem{AMS+2010}
J.~Alglave, L.~Maranget, S.~Sarkar and P.~Sewell. 
\newblock Fences in Weak Memory Models.
\newblock In {\em CAV}, pages(258-272), 2010.

\bibitem{AKN+2014}
J.~Alglave, D.~Kroening, V.~Nimal and D.~Poetzl. 
\newblock  Don't Sit on the Fence - A Static Analysis Approach to Automatic Fence Insertion.
\newblock In {\em CAV}, pages(508-524), 2014.

\bibitem{AKN+2013}
J.~Alglave, D.~Kroening, V.~Nimal and M.~Tautschnig. 
\newblock   Software Verification for Weak Memory via Program Transformation.
\newblock In {\em ESOP}, pages(512-532), 2013.

\bibitem{FBP2011}
M.~Faouzi, A.~Bouajjani and G.~Parlato.
\newblock Getting Rid of Store-Buffers in TSO Analysis.
\newblock In {\em CAV}, pages (99-115), 2011.

\bibitem{AAC+2013}
P. A.~Abdulla, M. F.~Atig, Y. F.~Chen, C.~Leonardsson and A.~Rezine.
\newblock Memorax, a Precise and Sound Tool for Automatic Fence Insertion under TSO.
\newblock In {\em TACAS}, pages(530-536), 2013.

\bibitem{AAC+2012}
P. A.~Abdulla, M. F.~Atig, Y. F.~Chen, C.~Leonardsson and A.~Rezine.
\newblock Automatic fence insertion in integer programs via predicate abstraction.
\newblock In {\em SAS}, pages(164-180), 2012.

\bibitem{HJM+2002}
T.A.~Henzinger, R.~Jhala, R.~Majumdar and G.~Sutre.
\newblock Lazy abstraction
\newblock In {\em POPL}, pages(58-70), 2002.

\bibitem{VN2011}
V.~Vafeiadis and F.Z.~Nardelli.
\newblock Verifying fence elimination optimisations
\newblock In {\em SAS}, pages(146-162), 2011.

\bibitem{BDM2013}
A.~Bouajjani, E.~Derevenetc and R.~Meyer.
\newblock Checking and Enforcing Robustness against TSO.
\newblock In {\em ESOP}, pages(533-553), 2013.

\bibitem{Rid2010}
T.~Ridge
\newblock A Rely-Guarantee proof system for x86-TSO.
\newblock In {\em VSTTE}, pages(55-70), 2010.

\bibitem{JLP+2014}
S.~Jagannathan, V.~Laporte, G.~Petri, D.~Pichardie and J.~Vitek.
\newblock Atomicity refinement for verified compilation.
\newblock In {\em PLDI}, pages(27-27), 2014.

\bibitem{KPH2010}
E.~Koskinen, M.~Parkinson and M.~Herlihy.
\newblock Coarse-grained transactions
\newblock In {\em POPL}, pages(19-30), 2010.

\bibitem{AC2009}
F.~Aleen and N.~Clark.
\newblock Commutativity analysis for software parallelization: letting program transformations see the big picture.
\newblock In {\em ASPLOS}, pages(241-252), 2009.

\bibitem{RD1997}
M.C.~Rinard and P.C.~Diniz.
\newblock Commutativity analysis: a new analysis technique for parallelizing compilers.
\newblock In {\em TOPLAS}, pages(942-991), 1997.

\bibitem{PGZ+2011}
P.~Prabhu, S.~Ghosh, Y.~Zhang, N.P.~Johnson and D.I.~August.
\newblock Commutative set: a language extension for implicit parallel programming.
\newblock In {\em PLDI}, pages(1-11), 2011.

\bibitem{Lip1975}
R.J.~Lipton.
\newblock Reduction: a method of proving properties of parallel programs.
\newblock In {\em CACM}, pages(717-721), 1975.

\bibitem{LFF2012}
H.~Liang, X.~Feng and M.~Fu.
\newblock A rely-guarantee-based simulation for verifying concurrent program transformations.
\newblock In {\em POPL}, pages(455-468), 2012.

\bibitem{JW2011}
A.J.~Turon and M.~Wand.
\newblock A separation logic for refining concurrent objects.
\newblock In {\em POPL}, pages(247-258), 2011.

\bibitem{Fen2009}
X.~Feng.
\newblock Local rely-guarantee reasoning.
\newblock In {\em POPL}, pages(315-327), 2009.

\bibitem{SSO+2010}
P.~Sewell, S.~Sarkar, S.~Owens, F.Z.~Nardelli and M.O.~Myreen.
\newblock x86-TSO: a rigorous and usable programmer's model for x86 multiprocessors.
\newblock In {\em CACM}, pages(89-97), 2010.

\bibitem{BA2008}
H.J.~ Boehm and S.V.~Adve.
\newblock Foundations of the C++ concurrency memory model.
\newblock In {\em PLDI}, pages(68-78), 2008.

\bibitem{BOS+2011}
M.~Batty, S.~Owens, S.~Sarkar, P.~Sewell and T.~Weber.
\newblock Mathematizing C++ concurrency.
\newblock In {\em POPL}, pages(55-66), 2011.

\bibitem{BWB+2011}
J.C.~Blanchette, T.~Weber, M.~Batty, S.~Owens and S.~Sarkar.
\newblock Nitpicking c++ concurrency.
\newblock In {\em PPDP}, pages(113-124), 2011.

\bibitem{SSA+2011}
S.~Sarkar, P.~Sewell, J.~Alglave, L.~Maranget and D.~Williams.
\newblock Understanding POWER multiprocessors.
\newblock In {\em PLDI}, pages(175-186), 2011.

\bibitem{HMS+2012}
S.M.~Haim, L.~Maranget, S.~Sarkar, K.~Memarian, J.~Alglave, S.~Owens, R.~Alur, M.M.K.~Martin, P.Sewell and D.~Williams.
\newblock An axiomatic memory model for POWER multiprocessors.
\newblock In {\em CAV}, pages(495-512), 2012.

\bibitem{AFI+2009}
J.~Alglave, A.Fox, S.Ishtiaq, M.O.~Myreen, S.Sarkar, P.Sewell and F.Z.~Nardelli.
\newblock The semantics of power and ARM multiprocessor machine code.
\newblock In {\em DAMP}, pages(13-24), 2009.

\bibitem{SVN+2013}
J.~Sevcik, V.~Vafeiadis, S.~Jagannathan and P.~Sewell.
\newblock CompCertTSO: A Verified Compiler for Relaxed-Memory Concurrency.
\newblock In {\em JACM}, 2013.




\end{thebibliography}




%\bibliography{tso-reduction-biblio}
% The bibliography should be embedded for final submission.


\end{document}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% Comments after this point %%%%%%%%%%%%
%%%%%%%%%%%%%%% Comments after this point %%%%%%%%%%%%
%%%%%%%%%%%%%%% Comments after this point %%%%%%%%%%%%
%%%%%%%%%%%%%%% Comments after this point %%%%%%%%%%%%
%%%%%%%%%%%%%%% Comments after this point %%%%%%%%%%%%
%%%%%%%%%%%%%%% Comments after this point %%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%











\COMMENT{
\paragraph{Triangular race.}
This code has a triangular race due to the first read of $Obj$, but before getting into that let us first discuss why the read of $Obj$ within the lock protected region does not lead to a triangular race.
Let us use $R_1$ and $R_2$ to denote the first and second read statements of $\alimemx {\tt Obj}$. 
Let $P$ be the program containing only {\tt DoubleCheckInit}.

Let $\alisequencex r$ be a TSO-run of the form 
\[
\alisequencex r = q_0\tau_1\cdot\ q\xrightarrow{\textnormal{\sc\small Rd},t:R_2}q'\ \cdot\tau_2q_n
\]
For $\alisequencex r$ to contain a triangular race, one condition requires that $t$ have done a write on some variable other than that is read by $R_2$, i.e. a local write statement to a location different from {\tt Obj} in $\tau_1$.
Such a write, the one that updates {\alimemx{l}} in order to acquire the lock, exists.
The second condition requires that another thread write concurrently to {\alimemx{\tt Obj}} as the first transition in $\tau_2$.
But clearly such a concurrent write cannot occur because all writes to {\alimemx{\tt Obj}} are protected by the lock and at the beginning of $\tau_2$, the thread $t$ holds the lock.
Thus, had it not been for the first read $R_1$, this procedure would have been triangular race-free and SC-like.

Now let us repeat the same consideration for $R_2$.
Let the TSO-run $\alisequencex r$ be in the form
\[
\alisequencex r = q_0\tau_1\cdot\ q\xrightarrow{\textnormal{\sc\small Wr},t:W_l}\cdot\ \tau_2\ \cdot q'\xrightarrow{}
\]

}

%%%%%%%%%%%%
%%%the following should go into the QED section where we describe how SC based analysis tools 
%%%can be used to decide the mover types of remote or local write actions.
%%%%%%%%%%%%%
\COMMENT{
We begin by describing a transformation which maps TSO programs to {\em equivalent} SC programs.
We should emphasize that our construction does not employ explicit arrays, but rather implicitly models the locally ordered buffered writes by simulating each thread with two threads.
The SC program enables us to apply reduction directly.
In particular, we show how mover types of certain statements can be used to conclude that a program cannot have any TSO distinguishing behavior.
Finally, we define an abstraction relation among TSO programs.
This abstraction forms the pillar of a reasoning methodology which enables one to start with a program with TSO distinguishing behavior and to end with a more abstract program which is SC-like.


\begin{figure*}
\begin{tabular}{p{.4\textwidth}p{.3\textwidth}p{.3\textwidth}}
\begin{alltt}\(ReadL(e,r,l\sb{s})\) \{\COMMENT{ \(\aliatomic\) \{   }                                 
 if (UCntL[\(e\)][tid]>UCntR[\(e\)][tid])       
  \{\(r\) := \(e\sp{loc}\);\} \{\(r\) := \(\alimemx{e}\);\}                      
 ReadVal[\(l\sp{loc}\sb{s}\)][tid] := \(r\);               
 \(l\sp{loc}\sb{s}\)[tid]++;
\}

\(ReadR(e,r,l\sb{s})\) \{
 \(\aliassume\) \(l\sp{rem}\sb{s}\)[tid] < \(l\sp{loc}\sb{s}\)[tid];
 r := ReadVal[\(l\sp{rem}\sb{s}\)][tid];
 \(l\sp{rem}\sb{s}\)[tid]++;
\}
\end{alltt} &

\begin{alltt}\(WriteL(e,r,l\sb{s})\) \{
 \(e\sp{loc}\) := \(e\);
 \(l\sp{loc}\sb{s}\)[tid]++;
 UCntL[\(e\)][tid]++;

\(WriteR(e,s,l\sb{s})\) \{
 \(\aliassume\) \(l\sp{rem}\sb{s}\)[tid] < \(l\sp{loc}\sb{s}\)[tid];
 \(\alimemx{e}\) := WriteVal[\(l\sp{loc}\sb{s}\)][tid];
 \(l\sp{rem}\sb{s}\)[tid]++;
 UCntR[\(e\)][tid]++;
\}\end{alltt} & 

\begin{alltt}
\(FenceL\) \{
 \(\aliassume \forall e.\) 
   UCntL[\(e\)][tid]
        ==
   UCntR[\(e\)][tid];
\}

\(FenceR\) \{
 \(\aliskip\);
\}\end{alltt}
\end{tabular}
\caption{The TSO to SC transformation macros.}
\label{fig:transformation-macros}
\end{figure*}

\subsection{Program transformation.}
\label{subsec:program-transformation}
Let $P=(\{M_1,\ldots,M_n\},\alilabel)$ be a labeled program.
For notational convenience, we let $l_s$ to denote the label $l$ of $s$, i.e. $\alilabelx s=l$.
The {\em split transformation} of $P$ is another program $\alisplitprogx P=(\{M^{loc}_1,M^{rem}_1,\ldots,M^{loc}_n,M^{rem}_n\},\alilabel')$, whose components are explained below.

Let $s$ be a statement in $M_i$.
The {\em local transformation} and the {\em remote transformation} of $s$, written as $\aliloctransx s$ and $\aliremtransx s$ respectively, are given below:
\begin{eqnarray*}
 \aliloctransx s  & \stackrel{def}{=} &
  \begin{cases}
   \aliatomicx {ReadL(e,r,l_s)} & , s=r:=\alimemx e\\
   \aliatomicx {WriteL(e,r,l_s)} & , s=\alimemx e:= r\\
   \aliatomicx {FenceL} & , s=\alifence\\
   s & , \textnormal{otherwise}
  \end{cases}\\
 \aliremtransx s & \stackrel{def}{=} &
  \begin{cases}
   \aliatomicx {ReadR(e,r,l_s)} & , s=r:=\alimemx e\\
   \aliatomicx {WriteR(e,r,l_s)} & , s=\alimemx e:= r\\
   \aliatomicx {FenceR} & , s=\alifence\\
   s & , \textnormal{otherwise}
  \end{cases}
\end{eqnarray*}
By convention, we let $\aliloctransx \varepsilon=\aliremtransx \varepsilon=\varepsilon$.

These transformations are used to implicitly represent the store buffer.
The local transformation of a read statement $r\mathtt{:=}\alimemx e$ checks whether the latest update to $\alimemx e$ by this thread is still in its buffer.
If so, the value to be read from the buffer is mimicked by reading the new auxiliary variable $e^{loc}$ as seen by this thread.
Otherwise, the value is read from the memory, i.e. the contents of $\alimemx e$.

Both of these transformations are extended to code blocks respecting the program order.
Formally, if $C=s;C'$ is a code block, $\aliloctransx C$ and $\aliremtransx C$ are given by $\aliloctransx s; \aliloctransx {C'}$ and $\aliremtransx s; \aliremtransx {C'}$, respectively.
This way we identify each method $M_i=\{C_i\}$ with two methods $M^{loc}_i=\{\aliloctransx {C_i}\}$ and $M^{rem}_i=\{\aliremtransx {C_i}\}$ by applying $\aliloctrans$ and $\aliremtrans$ to each statement in $M_i$.
}
\COMMENT{
We call an SC run of $\alisplitprogx P$ {\em well-formed} if 
\begin{itemize}
\item it admits a partitioning $\aliloctransx T$ and $\aliremtransx T$ of $T$ such that $t\in\aliloctransx T$ iff 
\item there is a bijection $\mu$ among the set of thread and method pairs $(t,m)$ such that if $\mu(t,m)=(t',m')$, then $t$ is executing $m$ , $t'$ is executing $m'$, $t\neq t'$ and there is a method $\hat{m}$ with $m=\aliloctransx \hat{m}$ and $m'=\aliremtransx \hat{m}$.
\end{itemize}
}

\COMMENT{
%Intuitively, a well-formed run will have both the local and remote copy of a method (never only one of them)
The transformation as defined is both sound and complete which is given as the main result of this section.


\begin{theorem}
Let $P$ be a labelled program.
The TSO runs of $P$ and the SC runs of $\alisplitprogx P$ are isomorphic up to the rearrangement of the initialization of the remote methods, $M^{rem}_i$.
\end{theorem}
\begin{proof}[Sketch]
Let $\alisequencex r$ be a TSO run of $P$.
Then a run of $\alisplitprogx P$ is constructed by replacing all {\sc\small Init} transitions done by $t$ for method $m$ with an {\sc\small Init} transition done by $t^{loc}$ for $m^{loc}$ immediately followed by another {\sc\small Init} transition done by $t^{rem}$ for $m^{rem}$.
All local write transitions {\sc\small WrB} by $t$ are replaced with {\sc\small Wr} transitions by $t^{loc}$.
Similarly all buffered write transitions {\sc\small WrM} by $t$ are replaced with {\sc\small Wr} transitions by $t^{rem}$.
Each fence transition due to statement $s$ of $m$ by $t$ is replaced with $\aliremtransx s$ of $m^{rem}$ by $t^{rem}$.
By an inductive argument, in such cases the predicate in the assume instruction of $\aliremtransx s$ evaluates to true.

The construction in the other direction first moves all initialization transitions {\sc\small Init} of remote copies, i.e. $m^{rem}$ by some $t^{rem}$ immediately after its associated {\sc\small Init} transition of $m^{loc}$.
The replacement of the initialization of 
\end{proof}
}

%We now present a mapping which will output another program $P'$ such that there exists a bijection between $\alirunsx {tso} P$ and $\alirunsx {sc} P$. 



\COMMENT{
Observe that according to Def.~\ref{def:movers}, in order to prove that a statement $s$ is a left-mover we only need to check whether $s$ moves to the left of those statements with which $s$ can simultaneously execute. 
Let us consider a particular instance where $s^{loc}$ is a local write action executed by thread $t$, $s$ is its matching remote write action, and all occurrences of $s^{loc}$ are preceded by a fence statement executed by $t$.
This means that between $s^{loc}$ and $s$ there could be no remote write actions done by $t$.
This in turn implies that if $s$ is left-mover, then the combined write action is atomic.
}


 


\COMMENT{

\begin{definition}[Movers]
Let $\mathbf{E}$ be a set of TSO-executions, and $\aliequivgeneric$ be an equivalence relation over $\mathbf{E}$.
Let $a$ be some TSO action that occurs in some TSO-execution in $\mathbf{E}$.
Then, $a$ is called a {\em left mover per $\aliequivgeneric$} if for any TSO-execution $\mathbf{e}\in\mathbf{E}$ in which $a$ occurs, there is another TSO-execution $\mathbf{e}'\in\mathbf{E}$ such that $\mathbf{e}\aliequivgeneric\mathbf{e}'$ and each occurrence of $a$ in $\mathbf{e}'$ is either immediately preceded by actions that precede $a$ in $\alipotsox {\mathbf{e}'}$ or the first action in $\mathbf{e}'$.

Similarly, $a$ is called a {\em right mover per $\aliequivgeneric$} if for any TSO-execution $\mathbf{e}\in\mathbf{E}$ in which $a$ occurs, there is another TSO-execution $\mathbf{e}'\in\mathbf{E}$ such that $\mathbf{e}\aliequivgeneric\mathbf{e}'$ and each occurrence of $a$ in $\mathbf{e}'$ is either immediately followed by actions that succeed $a$ in $\alipotsox {\mathbf{e}'}$ or the last action in $\mathbf{e}'$.
\end{definition}

The preceding definition is more general than the classical definition of reduction which fixes the interpretation of $\aliequivgeneric$: two executions are equivalent if they have identical end-states.
The reason for the added flexibility should become clear when we introduce abstraction for programs.
However, we will drop the mention of the equivalence relation whenever it is irrelevant to the discussion or clear from the context.

Typically, one relies on an inductive argument to show that a particular action is a mover.
Let $\mathbf{e}$ be a TSO-execution in $\mathbf{E}$.
We say that $\mathbf{e}[i]$ moves to the left of $\mathbf{e}[i-1]$ if there is a TSO-execution $\mathbf{e}'$ such that $\mathbf{e}\aliequivgeneric\mathbf{e}'$, $\mathbf{e}\langle 1,i-2\rangle\cdot\mathbf{e}[i]=\mathbf{e}'\langle 1,i-1\rangle$ and $|\mathbf{e}|\geq|\mathbf{e}'|$.
Intuitively, we stay in the same equivalence class by moving $\mathbf{e}[i]$ one step to the left (towards the beginning of the sequence). 
Then, if one can show that a particular action $a$ moves to the left of all actions $b$ that can immediately precede $a$ except for those $c$ such that $c\alipotsox {\mathbf{e}} a$, then $a$ will be shown to be a left-mover in that equivalence class.
%These arguments will be readily used to argue the mover types of statements of a program.  

\begin{lemma}
Let $\mathbf{e}$ be a TSO-execution and let $A_r$ denote the set of actions $\{\mathbf{e}[i] \mid \mathbf{e}[i]\in\tsoalph_{\remwrite,-,-}\}$ and $A_l$ denote the set of actions $\{\mathbf{e}[i] \mid \mathbf{e}[i]\in\tsoalph_{\locwrite,-,-}\}$.
If each action in $A_r$ is a left-mover or each action in $A_l$ is a right-mover in $[\mathbf{e}]_{\tsoequiv}$, then $\mathbf{e}$ is SC-like.
\end{lemma}

Thus, it is sufficient to show that all remote write actions are left-movers or all local write actions are right-movers to conclude that a TSO-execution is SC-like.
It is possible to weaken the condition further as follows.

\begin{corollary}

\end{corollary}


}



\COMMENT{
Consider the code given in Fig.~\ref{fig:store-buffer}, which is derived from a classic example illustrating the main behavioral difference between TSO and SC architectures.
\begin{figure}[h]
\begin{tabular}{p{.14\textwidth}p{.14\textwidth}p{.14\textwidth}}
\begin{alltt}m1()
\{
 \(A\):=1;
 \(\alireg\)[1]:=\(B\);
\}\end{alltt} 
&
\begin{alltt}m2()
\{
 \(B\):=2;
\}\end{alltt}
&
\begin{alltt}m3()
\{
 \(\alireg\)[1]:=\(B\);
 \(\alireg\)[2]:=\(A\);
\}\end{alltt}\\
\multicolumn{3}{l}%
{$\locwritex t A 1 \cdot \alireadx t B 0 \cdot \locwritex u B 2 \cdot \remwritex u B 2$}\\
\multicolumn{3}{c}%
{$ \cdot\ \alireadx v B 2 \cdot \alireadx v A 0 \cdot \remwritex t A 1$}
\end{tabular}
\caption{Store buffering with non SC-like memory trace.}
\label{fig:store-buffer}
\end{figure}
The memory trace given in Fig.~\ref{fig:buffer-store} is TSO compliant.
It belongs to a run in which thread $t$ runs {\tt m1}, $u$ runs {\tt m2} and $v$ runs {\tt m3} exactly once.




In the remainder of this section, we work through an example program which contains a triangular race and hence is not initially amenable to an SC analysis.
We show how abstracting the program leads to a program which is SC-like.
}


\COMMENT{
Consider a sequence of memory accesses done by two threads, $t$ and $u$, given as:
\[
{\aliwritex t y 1}\ \cdot\ {\alireadx t x 0}\ \cdot\ {\aliwritex u x 2}
\]
%Informally, this represents a sequence with an arbitrary sequence of memory operations followed by a write to $y$ by thread $t$ followed by a (possibly empty) sequence of reads done by $t$ followed by a read to $x$ followed by a write $x$ by a different thread $u$.
This represents a sequence of a write to $y$ of value 1 by thread $t$, followed by a read of $x$ returning 0 again by $t$, followed by a write to $x$ of 2 by thread $u$.

To see why this is a {\em bad} (non-SC) sequence for TSO, we will refer to an alternative characterization of memory accesses in TSO.
We represent read accesses as usual, but change the way write accesses are represented.
We split each write access $W$ into two distinct accesses, {\locwrite} and {\remwrite}.
Each sequence over simple memory accesses as given above will be identified with a set of sequences over the new alphabet such that i) each {\aliwrite} is replaced with {\locwrite}, ii) each {\locwrite} has a matching {\remwrite} such that the thread local order among {\locwrite}'s is preserved by their associated {\remwrite}'s.
For instance, the following sequence is one possible TSO-expansion of the SC-sequence above.
\[
{\locwritex t y 1}\ \cdot\ {\alireadx t x 0}\ \cdot\ {\locwritex u x 2}\ \cdot\ {\remwritex u x 2}\ \cdot\ {\remwritex t y 1}
\]
Observe that the ordering between the remote updates to $y$ and $x$ is the opposite of the ordering between their corresponding local updates. 
Intuitively this means that the order of updates to $x$ and $y$ as seen by $t$ ($y$ precedes $x$) and the order seen by a different thread $v$ ($x$ precedes $y$) will be different, which is impossible under SC.

We show that a similar characterization can be obtained using reduction arguments.
An execution can be generated under SC if it is possible to {\em move} all local and their matching remote updates next to each other without changing the end state of the execution.
For the example above, the question is whether it is possible to move either $\remwritex t y \dontcare$ to the left of every possible concurrent action or $\locwritex t y \dontcare$ to the right of every possible concurrent action.
The trace above itself is not problematic because both remote writes are left-movers. 
In other words, the above trace is equivalent to the following:
\[
{\locwritex t y 1}\,\cdot\,{\remwritex t y 1}\,\cdot\,{\alireadx t x 0}\,\cdot\,{\locwritex u x 2}\,\cdot\,{\remwritex u x 2}
\]
However, in the presence of other writes such a transformation can become impossible.
Consider for instance
\begin{eqnarray*}
&{\locwritex t y 1}\,\cdot\,{\alireadx t y 1}\,\cdot\,{\alireadx t x 0}\,\cdot\,{\locwritex u x 2}\,\cdot\,{\alireadx u x 2}\,\cdot\,{\alireadx u y 0}\\
&\cdot\ {\remwritex u x 2}\,\cdot\,{\remwritex t y 1}
\end{eqnarray*}
It is possible to move the local and remote writes to $x$ done by thread $u$ without changing the values read.
However, it is impossible to make the local and remote writes to $y$ done by thread $t$ without changing one of the reads: if $\remwritex t y 1$ is to the left of $\locwritex u x 2$, the read of $y$ by thread $u$ will return 1 instead of 0; if the $\locwritex t y 1$ is to the right of $\locwritex u x 2$, the read of $x$ by thread $t$ will return 2 instead of 0.

\begin{figure}[t]
\begin{alltt}
Recv()          Send(d)
 while (R);      while (!R);
 d := Data;      Data := d;
 R := \(\alitrue\);       R := \(\alifalse\);
 return d;\end{alltt}
\caption{A binary synchronous rendez-vous with two threads.}
\label{fig:rendez-vous}
\end{figure}
Consider a simple template for a binary synchronous rendez-vous message passing as given in Fig.~\ref{fig:rendez-vous}.
There are two methods, {\tt Recv} and {\tt Send}.
The receiver method {\tt Recv} spins for the flag {\tt R} until it is set to false.
Once that happens, it reads the value stored in {\tt Data}, resets {\tt R} to true and returns the value it has read.
The sender method {\tt Send} operates dually: it spins on {\tt R} until it is set to true, updates the value in {\tt Data} and resets {\tt R} to false.

Recall that a write can be treated as atomic if for any execution in which both its local and remote updates occur, one can find an equivalent execution in which they occur consecutively. 
For instance, if we want to show that the write to {\tt R} done by {\tt Recv} is atomic, we have to show that if the following is an execution
\[
A\,\cdot\,{\locwritex t R {\alitrue}}\,\cdot\,B\,\cdot\,{\remwritex t R {\alitrue}}
\]
there is a partitioning of $B$ into $B_1$ and $B_2$ such that
\[
A\,\cdot\,B_1\,\cdot\,{\locwritex t R {\alitrue}}\,\cdot\,{\remwritex t R {\alitrue}}\,\cdot\,B_2
\]
is also an execution.
One can construct such an execution because i) one can always move a local update to the right of other thread's actions, ii) there cannot be any remote updates to $R$ in the sequence of accesses represented by $B$, iii) thus it is safe to move any reads of $R$ done by a subsequent call to {\tt Send} all of which will return {\alitrue}.
Thus setting $B_1=B$ and $B_2=\varepsilon$ gives the desired execution.
Similar arguments are used to prove that all the write accesses in Fig.~\ref{fig:rendez-vous} are atomic.

\paragraph{Abstracting memory accesses.}

\paragraph{Transforming TSO into SC.}

\paragraph{Local analysis for reduction.}
Once the program is transformed, one can appeal to the reduction theorems for TSO.
}
